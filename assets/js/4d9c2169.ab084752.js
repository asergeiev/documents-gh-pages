"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[4937],{3905:function(e,t,n){n.d(t,{Zo:function(){return d},kt:function(){return m}});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function c(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=r.createContext({}),l=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},d=function(e){var t=l(e.components);return r.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},p=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,s=e.parentName,d=c(e,["components","mdxType","originalType","parentName"]),p=l(n),m=a,h=p["".concat(s,".").concat(m)]||p[m]||u[m]||i;return n?r.createElement(h,o(o({ref:t},d),{},{components:n})):r.createElement(h,o({ref:t},d))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,o=new Array(i);o[0]=p;var c={};for(var s in t)hasOwnProperty.call(t,s)&&(c[s]=t[s]);c.originalType=e,c.mdxType="string"==typeof e?e:a,o[1]=c;for(var l=2;l<i;l++)o[l]=n[l];return r.createElement.apply(null,o)}return r.createElement.apply(null,n)}p.displayName="MDXCreateElement"},4743:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return c},contentTitle:function(){return s},metadata:function(){return l},toc:function(){return d},default:function(){return p}});var r=n(7462),a=n(3366),i=(n(7294),n(3905)),o=["components"],c={id:"architecture-and-scalability",title:"Architecture and Scalability",sidebar_label:"Architecture and Scalability"},s="Architecture and Scalability",l={unversionedId:"architecture-and-scalability",id:"architecture-and-scalability",isDocsHomePage:!1,title:"Architecture and Scalability",description:"CompreFace is delivered as a docker-compose file by default, so you can",source:"@site/docs/Architecture-and-scalability.md",sourceDirName:".",slug:"/architecture-and-scalability",permalink:"/documents/docs/architecture-and-scalability",editUrl:"https://github.com/facebook/docusaurus/edit/master/website/docs/Architecture-and-scalability.md",tags:[],version:"current",frontMatter:{id:"architecture-and-scalability",title:"Architecture and Scalability",sidebar_label:"Architecture and Scalability"},sidebar:"someSidebar",previous:{title:"Configuration",permalink:"/documents/docs/configuration"},next:{title:"Custom Builds",permalink:"/documents/docs/custom-builds"}},d=[{value:"CompreFace architecture diagram",id:"compreface-architecture-diagram",children:[],level:2},{value:"Balancer + UI",id:"balancer--ui",children:[],level:2},{value:"Admin server",id:"admin-server",children:[],level:2},{value:"API servers",id:"api-servers",children:[],level:2},{value:"Embedding Servers",id:"embedding-servers",children:[],level:2},{value:"PostgreSQL",id:"postgresql",children:[],level:2}],u={toc:d};function p(e){var t=e.components,n=(0,a.Z)(e,o);return(0,i.kt)("wrapper",(0,r.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"architecture-and-scalability"},"Architecture and Scalability"),(0,i.kt)("p",null,"CompreFace is delivered as a docker-compose file by default, so you can\neasily start it with one command. However, CompreFace could be scaled up\nto distribute computations on different servers and achieve high\navailability. This section describes the architecture of CompreFace,\neach of its components, and suggestions on how to scale the system."),(0,i.kt)("h2",{id:"compreface-architecture-diagram"},"CompreFace architecture diagram"),(0,i.kt)("p",null,"CompreFace architecture diagram"),(0,i.kt)("h2",{id:"balancer--ui"},"Balancer + UI"),(0,i.kt)("p",null,"Container name in the docker-compose file: compreface-fe"),(0,i.kt)("p",null,"This container runs Nginx that serves CompreFace UI."),(0,i.kt)("p",null,"In the default config, it's also used as the main gateway - Nginx\nproxies user requests to admin and API servers."),(0,i.kt)("h2",{id:"admin-server"},"Admin server"),(0,i.kt)("p",null,"Container name in the docker-compose file: compreface-admin"),(0,i.kt)("p",null,"Admin server is a Spring Boot application, and it's responsible for all\noperations that are done on UI. Admin server connects to PostgreSQL\ndatabase to store the data."),(0,i.kt)("h2",{id:"api-servers"},"API servers"),(0,i.kt)("p",null,"Container name in the docker-compose file: compreface-API"),(0,i.kt)("p",null,"API servers handle all user API calls: face recognition, face detection,\nand face verification."),(0,i.kt)("p",null,"It provides API key validation, proxies images to Embedding servers, and\nclassifies the face. For face classification, we use the ND4J library."),(0,i.kt)("p",null,"By default, the number of API servers in the config is 1, but for production\nenvironments to increase possible bandwidth and achieve high\navailability, there should be at least two such servers, and they should\nbe on different machines. In addition, the data synchronization is\nimplemented via PostgreSQL notifications, so if, for example, you add a\nnew face to a collection, all other servers know about it and can\nrecognize this new face."),(0,i.kt)("p",null,"Classification is not a very heavy operation as embedding calculation\nand doesn't require GPU in most cases. API server connects to PostgreSQL\ndatabase to store the data."),(0,i.kt)("p",null,"There is a PYTHON_URL environment variable that tells this container where\nto send requests to compreface-core containers.\nDefault value: http://compreface-core:3000."),(0,i.kt)("h2",{id:"embedding-servers"},"Embedding Servers"),(0,i.kt)("p",null,"Container name in the docker-compose file: compreface-core"),(0,i.kt)("p",null,"The embedding server is responsible for running neural networks. It\ncalculates embeddings from faces and makes all plugin recognitions like\nage and gender detection. These servers are stateless, don't have a\nconnection to a database, and don't require any synchronization between\nthem."),(0,i.kt)("p",null,"By default, the number of API servers in the config is 1, but for production\nenvironments to increase possible bandwidth and achieve high\navailability, there should be at least two such servers, and they should\nbe on different machines."),(0,i.kt)("p",null,"Running neural networks is a complicated operation. Therefore, the total\nperformance of the system highly depends on these nodes. That is why we\nrecommend using highly performant nodes to run Embedding Servers,\nideally with GPU support. To learn more about how to run CompreFace with\nGPU, see custom ",(0,i.kt)("a",{parentName:"p",href:"/documents/docs/custom-builds"},"builds documentation"),"."),(0,i.kt)("h2",{id:"postgresql"},"PostgreSQL"),(0,i.kt)("p",null,"Default docker-compose configuration includes postgreSQL database."),(0,i.kt)("p",null,"If you want CompreFace to connect to your database, you need to provide\nsuch environment variables for compreface-admin and compreface-API\ncontainers: ","*"," POSTGRES_PASSWORD ","*"," POSTGRES_URL ","*"," POSTGRES_USER"))}p.isMDXComponent=!0}}]);